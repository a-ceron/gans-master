\documentclass[letterpaper,12pt,oneside]{book}
%\usepackage[a4paper,includeall,bindingoffset=0cm,margin=2cm,marginparsep=0cm,marginparwidth=0cm]{geometry}

    %Paquetes propios de la plantilla
    \usepackage[top=1in, left=0.9in, right=1.25in, bottom=1in]{geometry}
    \usepackage{bachelorstitlepageUNAM}
    \usepackage[utf8]{inputenc}
    
    %Paquetes personales
    \usepackage{fontawesome5}
    
    \usepackage{float}
    \usepackage{graphicx}
    \usepackage[table,xcdraw]{xcolor}
    \usepackage[T1]{fontenc}
    \usepackage[spanish,es-nodecimaldot,es-tabla]{babel}
    \usepackage{tikz} 
    \usepackage{tocloft}
    \usepackage{setspace}
    \usepackage[nottoc]{tocbibind}
    \usepackage[colorlinks,citecolor=red,urlcolor=blue,bookmarks=false,hypertexnames=true]{hyperref} 
    \usepackage{csquotes}
    \usepackage{changepage}
    
     \graphicspath{{./figs/}}

    %Comandos personalizados---------
    \newcommand{\figura}[4]{
          \begin{figure}[H]
            \centering
            \includegraphics[scale=#1]{#2}
            \caption{#3}
            \label{#4}
          \end{figure}
                            }
    \newcommand{\refig}[1]{\figurename~\ref{#1}}
    \newcommand{\refeq}[1]{\textbf{ecuación}~\ref{#1}}
    \newcommand{\reteo}[1]{$\mathfrak{Teorema}$~\ref{#1}}
    \newcommand{\bb}[1]{\{#1\}}
    \newcommand{\dd}[2]{ \frac{ #1 }{ #2 } }
    \newcommand{\vals}[2]{ #1$\,$#2 }
    \newcommand{\quotes}[1]{``#1''}
 

    \newtheorem{defi}{\textit{\textmd{$\mathfrak{Definición}$} }}
    \newtheorem{teo}{\textit{\textmd{$\mathscr{Teorema}$} }}


    \renewcommand\cftsecpresnum{\S}
    \renewcommand\cftsubsecpresnum{\S}   

    %Referencias bibliográficas
    \usepackage[ backend=biber,
                 style=apa,
                 uniquename=init,%Requerido para el de abajo
                 minnames=1,
                 maxnames=2,%<----- reduce the number of names on the citation
                 citestyle=authoryear-icomp]{biblatex}
    \addbibresource{bibfile.bib}

%borrar-----------
    \makeatletter
    \let\NAT@parse\undefined
    \makeatother
%borrar-----------
%###################################
% Artículo 12.- El protocolo de tesis, con el visto bueno de un asesor, deberá ser entregado por 
% el alumno a la Coordinación de Carrera correspondiente para su registro, así como para su 
% presentación ante el Comité de Aprobación de Protocolo de Tesis correspondiente. El alumno 
% deberá tener un mínimo del 90% de créditos de su carrera para registrar su protocolo. La 
% Coordinación de Carrera será la responsable de realizar las gestiones académico-administrativas de 
% esta opción de titulación.
% Para someter el protocolo de tesis al Comité de Aprobación de Protocolo de Tesis respectivo, se 
% deberá entregar un documento que no exceda de cinco cuartillas, además de la portada, 
% considerando el contenido siguiente:
%    a) Portada, la cual deberá incluir: título del trabajo de tesis, nombre del alumno y nombre del asesor;
%    b) Objetivo(s) del trabajo;
%    c) Índice tentativo del trabajo de tesis;
%    d) Introducción, antecedentes y justificación del trabajo;
%    e) Metodología a emplear, y
%    f) Bibliografía básica (mínimo 10 referencias)
%###################################

    %Portada------------------------
    \author{Ariel Cerón González}
    \title{Generación de imágenes con efecto lente gravitacional a partir de pocos ejemplo usando redes generativas antagónicas}
    \faculty{Posgrado en Ciencia e Ingienería de la Computación}
    %\faculty{Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas}
    \degree{Maestro en Ciencia e Ingeniería de la Computación}
    \supervisor{Dr. Gibran Fuentes Pineda\\ IIMAS, UNAM}
    \cityandyear{CDMX, 2023}
    \logouni{Imagenes/Formales/Escudo-UNAM}
    \logofac{Imagenes/Formales/Escudo-Posgrado}


    \begin{document}    
        %Portada------------------------------
        \frontmatter
        \maketitle
        
        %Oración mamadora--------------------
        \chapter*{}
            \begin{flushright}%
                \vspace*{0.5cm}
                \thispagestyle{empty}
                Machine learning methods implement the scientific principle of “trial and error”.\\

                    \cite{jung2022ml}
            \end{flushright}
            
        %Reumen-----------------------------
        \chapter*{}
        \vspace*{-1.5 cm}
            \begin{center}
                {\LARGE{\bf RESUMEN}}\\
            \end{center}   
                Bajo ciertas condiciones la gravedad genera efectos visuales interesantes. El efecto de {\it lente gravitacional}, descrito por primera vez en la teoría general de la relatividad de Einstein, es un ejemplo. 
                
                Descrito como la alteración espacial realizada por objetos masivos, como colecciones de galaxias, que puede crear campos gravitacionales que distorcionan y magnifican la luz proveniente de galaxias distantes que se encuentran en la misma línea de visión. 

                Existen algunos telescópios, como el Hubble o Euclid, capaces de observar este fenómeno, sin embargo su identificación, y en especial su confirmación, es una tarea difícil lo que explica que a la fecha solo se tenga una centena de datos confirmados.
                
                Las observaciones de este fenómeno pueden ayudar en el estudio de galaxias primitivas, conocer mejor la distribución de las galaxias o buscar exoplanetas que orbiten cerca de grandes soles. 

                Para aumentar la cantidad de elementos se han presentado trabajos que entrenan modelos de clasificación para  ayuden a identificar posibles registros del fenómeno en los datos que los telescopios mencionados han registrado, llegando a tener porcentajes del 88\% de éxito en la identificación.

                El éxito de los modelos de aprendizaje se distribuye en sus componentes principales: los datos, el modelo y la función de pérdida. Cuando alguno de estos elementos tienen deficiencia, el modelo presenta problemas los resultados, un ejemplo es la carencia de datos de calidad, como en el caso del lente gravitacional. 

                Los modelos generativos antagónicos (GAN), por su parte, han sido descritos e implementados de diferentes formas mostrando buenos resultados en la generación de rostros, color de autos o en la identificación de razas de perro; aplicando diferentes condiciones como la poca disponibilidad de datos, diferente calidad de imágenes, poca diversidad en las imágnes, pocos datos de entrenamiento, entre otros.

                Este trabajo se centra en estudiar el problema de la selección de modelo para entrenar modelos GANs con pocos datos que replique el efecto lenticular en nuevos conjuntos de datos, considerando tres estrategías de evaluación 
                \begin{itemize}
                    \item[1.] Cálculo de la métrica FID (Fréchet inception distance) para establecer la calidad en las imágenes generadas. 
                    \item[2.] La puntación F1 con y sin aumentado de datos, del modelo entrenado, usando redes ResNet18 para la identificación de imágenes con efecto lenticular.
                    \item[3.] La revisión de un experto de los experimentos generados.  
                \end{itemize}

                {\bf Palabras clave:} GANs, efecto lenticular, redes profundas.


                
            %{\it Resumen en ingles}\\
                ------------------\\
                \vspace{0.5cm}
                
                \vspace{0.5cm}
                
            
        
        %Dedicatoria-------------------------
        \chapter*{}
            \begin{flushright}%
                \emph{Dedicatoria ...}                        
                \thispagestyle{empty}
            \end{flushright}
            
        %Agradecimientos---------------------
       
        \chapter{Agradecimientos}
             \spacing{1.5}%\doublespacing
                
        %Notación-----------------------------        
       
        \chapter{Notación}
            \begin{itemize}
                \item 
            \end{itemize}

        %Indice--------------------------------
        \newpage
        \tableofcontents
        \newpage
        \listoffigures

        \mainmatter

        %Contenido-----------------------------
       
        \chapter{Introducción}
            %El aprendizaje de máquina ajusta modelos matemáticos a partir del aprendizaje a través de la observación de datos, con el fin de responder una hipótesis. Son tres los elementos principales: 1) un conjunto de datos, 2) un conjunto de hipótesis y 3) una función de perdida que mide la calidad del aprendizaje o del ajuste del model. [\cite{prince2023understanding}]

            % Los modelos generativos son modelos enfocados en la generación de texto, imágenes u otro tipo de datos a partir de una entrada. Un modelo antagónico generativo (Generative Adversarial Network, GAN) es un tipo de modelo no supervisado que genera nuevos ejemplos indistinguibles a un conjunto de entrenamiento. 

            Mirar al cielo dejo de ser una actividad para sonambulos y se convirtió en una ciencia que ha desarrollado herramientas para conocer la historia del universo. La formalización de esta ciencia, o lo que se conoce como la fundación de la astronomía moderna, se dió en el Renacimiento (siglo XVI) gracias al modelo matemático heliocéntrico del movimiento planetario propuesto por Copérnico. A la fecha, la astronomía puede dividirse en dos grandes ramas: teórica y observacional. La primera consiste, a grandes rasgos, en la creación y verificación de modelos basados en observaciones o simulaciones, mientras que la segunda consiste en el estudio de la estructura, evolución y origen del universo a partirde las propiedades físicas y químicas a través de observaciones derivadas de telescopios y/o detectores.

            El interés de este trabajo se centra en el área de la astronomía observaciona, en particular en un fenómeno denomidado {\it efecto lenticular} descrito por primera vez en la teoría general de la relatividad. Este efecto se presenta  cuando una gran cantidad de materia, como conjuntos de galaxias, crean un campo gravitacional que puede distorcionar y, como una lupa, modificar la luz proveniente de galaxias que se encuentran detras pero en la misma línea de visión. 
            
            Trayendo contribuciones en el estudio de galaxias primitivas o en la detección de exoplanetas, sin embargo la detección e identificación de este fenómeno no es un ejercicio sencillo y se requiere de telescopios como el {\it Hubble} y {\it Euclid} junto a un equipo observatorio como el {\it Vera Rubin Observatory Legacy Survey of Space and Time}, que puedan recopilar, identificar y confirmar la presencia de diversos fenómentos, como el de el efecto lenticular. En la actualidad solo hay un ciento de imágenes que, genuinamente, presentan este fenómeno lo que ha abierto la puerta a equipos de trabajo que buscan facilitar este actividad. 

            Una herramienta que sale a la luz es el uso de modelos de aprendizaje maquina, en especifico modelos de clasificación que puedan identificar el fenómeno en imágenes espaciales. no obstante, la falta de conjuntos de entrenamiento ha suponido un reto en el entrenamiento de los modelos [\cite{madireddy2019modular}, \cite{wilde2022detecting}, \cite{tran2022agel}].

            Los modelos GANs (Generative Adversarial Network) se han establecido como el estado del arte actual en la generación de imágenes, debido al gran realismo mostrado en resultados con rostros humanos, colores en automóviles, razas de perros, entre otros. Este tipo de modelo no supervisado ha presentado diferentes variables que permiten resolver algunos problemas presentados en la implementación inicial de \cite{goodfellow2020generative}, como la inestavilidad en su convergencía, el colapso de la moda o la cantidad de imágenes necesarias para su entrenamiento. 
            
            Los modelos GAN han sido desarrollado principalmente para aquellos casos donde los datos son imágenes y dado a que hay diversas implementaciones que cubren los requerimentos de los datos, se vuelven ideales para este texto.


            % Poner merjor una hipótesis que aborde el tema de generación de imagenes con gans con pocos datos. solo eso distribución de imágenes con efecto lenticular y colocar los métodos q se usaron aumentado de datos, transferencia

            % Metodología: Cómo entrenar, cómo usar datos, cómo validar la hipótesis.

            La hipótesis de este trabajo se centra en el aprovechamiento de diferentes arquitecturas GANs para la generación de imágenes con efecto lenticular con pocas imágenes, que posteriormente puedan robustecer la base de datos con la que un modelo de clasificación sea entrenado, para mejorar la tasa de éxito. 

            \begin{itemize}
                \item[1.]Evaluar los resultados de diversas arquitecturas GAN, aplicando algunos métodos que reduzcan el costo computacional, el colapso de la moda, no sea necesario el uso de grandes conjuntos de datos y que acepten transferencia de conocimiento
                \item[2] Evaluación de los resultados en tres formas 1) con la ayuda de un experto, que visualmente confirme la afinidad de las imágenes generadas con las que puedan existir en la realidad, 2) usando FID para la evaluación de las imágenes generadas y 3) entrenando un modelo de clasificación que pueda reconocer imágenes reales de galaxia con efecto lenticular.  
            \end{itemize}
            
            


            
            
        \chapter{Los componentes de un modelo.}
            Los modelos de aprendizaje profundo, como las GANs, son un tipo de aprendizaje de máquina que ajusta modelos matemáticos a partir del aprendizaje obtenido en la observación de datos. Los elementos principales de un modelo de aprendizaje son: 1) un conjunto de datos, 2) un conjunto de hipótesis y 3) una función de perdida [\cite{prince2023understanding}]. 

            \section{Un conjunto de datos}
                Uno de los componentes principales en un modelo de aprendizaje es el conjunto de datos el cual se describe como  el conjunto de elementos que representan algún fenómeno de interes y se define como: 
                    \begin{equation}
                        \label{eq1:dataset}
                        \mathcal{D} = \bb{z^{(1)},\cdots, z^{(m)}}
                    \end{equation} 

                Siendo $z^{(i)} = {\bf x}$, $i \in I$ una imágen del conjunto de datos $\mathcal{D}$ y ${\bf x}$ representa los datos asociados a la imagen. En nuestro caso representa una matriz RGB. 

                    \subsection{Efecto lenticular }


                        Los rayos de luz son reflectados cuando se propagan a través de un campo gravitacional no homogeneo y aunque muchos investigadores tuvieron diferentes especulaciones acerca de este efecto, no fue sino hasta después de la presentación de la teoría general de la relatividad que se tuvo una hipótesis certera. [\cite{bermano2022state}]

                        Este fenómeno conocido como efecto lenticular (gravitational lensing) se genera por grandes concetraciones de masa que distorcionan el espacio a su alrededor. 
                        
                        Esta distorción puede observarse cuando una gran cantidad de materia, como conjuntos de galaxias, crean un campo gravitacional que distorciona y, como una lupa, magnifica la luz de galaxias distantes que se encuentran detras, pero en la misma línea de visión. Lo que permite a investigadores estudiar los detalles de galaxías primitivas que se encuentran tan alejadas como para ser vista con la tecnología actual.

                        \figura{1}{Imagenes/Resultados/space_15.png}{Una figura del conjunto de entrenamiento}{fig:rgb}

                        Identificar este efecto ha sido un reto difícil debido a la necesidad de combinar imágenes de alta resolución, reconocimiento de extensas áreas  y confirmación por espectrocopia. El efecto lenticular presenta una morfología compleja, y las fuentes de visión que la forma usualmente se mezclan al ser observados por algún artefacto terrestre.

            \section{Un conjunto de hipótesis}
                De forma general, se define como hipótesis a una familia de funciones que intentan, de alguna forma, aprender alguna caracteristica del conjunto de datos $\mathcal{D}$. 

                Nuestro escrito tiene como hipótesis principal al modelo conocido como {\bf red generativa adversaria }o GAN por sus siglas en ingles, {\it generative adversarial network} es un modelo no supervisado cuyo objetivo es el de generar nuevos ejemplos indistinguibles, a partirr de un conjunto de ejemplos de entraniento.
                
                \figura{0.25}{Imagenes/Resultados/gan_arc}{Arquitectura básica de un modelo GAN. Un vector ${\bf z}$ dek espacio latente pasa a través del modelo generador $g$ para crear un ejemplo ${\bf x^*}$. Se genera un conjunto de imágenes falsas $\bb{{\bf x^*}}$ e imágenes reales $\bb{{\bf x}}$ que pasan por el modelo discriminador $f$. Por último se modifican los parámetros de cada modelo y se repite el funcionamiento hasta que se llegue a una convergencia de Nash. [\cite{prince2023understanding}]}{fig:gan_arc}

                En 2014 se presenta {\it Generative Adversarial Net} el cual propone una arquitectura para la estimación de modelos generativos vía un entrenamiento adversario. 
                La arquitectura GAN se compone de dos modelos de redes neuronales, uno denominado generador, $G = [{\it z_j}, \theta]$ con ${\bf z_j}$ un vector del espacio latente y $\theta$ el conjunto de parámetros del modelo, cuyo encargo es el de generar nuevas instancias del mismo dominio que del conjunto de datos de origen, y un discriminador $D[{\bf x}, \phi]$ con $x$ un ejemplo y $\phi$ el conjunto de paráemtros del modelo, discrimina si los datos de entrada provienen el del dominio de datos de origen o si son imágenes del generador. Ambas redes se entrenan de manera conjunta, de manera que $G$ maximice sus posibilidades de no ser detectadas por $D$ y $D$ minimice la cantidad de malas detecciones. Estas dos redes adversarias compiten en un juego de suma cero en el que se hipotetiza que eventualmente llegan a un equilibrio de Nash.

                \subsection{Mode dropping}
                    Los modelos GANs son modelos relativamente sencillos que transforman ruido aleatorio en datos indistinguibles a un conjunto de entrenamiento. Sin embargo, los modelos GAN originales presentan diferentes problemas durante el entrenamiento y después. 

                    Un problema común del modelo es cuando genera ejemplos plausibes pero solo representan un subconjunto específico de los datos, por ejemplo si el modelo esta generando rostros y ocurre este problema, puede que no genere nunca imágenes con barba. Una versión extrema de este problema ocurre cuando el modelo ignora por completo el vector latente ${\bf z}$ y colapsa a un conjunto específico de ejemplos, este probelma se conoce como colapso de la moda (mode collapse).

                    Esto ocurre por la definición propuesta en el modelo GAN original 
                    
                    \begin{eqnarray}
                        \label{eq:loss_gan_origin}
                        L[\phi] &=& \sum -\log[1 - sig[D[G[{\bf z_j, \theta}],\phi]]] - \sum \log[sig[D[{\bf x_i}, \phi]]]\\
                        L[\theta] &=& \sum log[1 - sig[D[G[{\bf z_j}, \phi]]]]
                    \end{eqnarray}

                    Esta función penaliza regiones con ejemplos reales pero no muestras, lo que fuerza a una convergencia. Si nos fijamos en la ecuación \ref{eq:loss_gan_origin} podemos observar que el segundo término de la primera ecuación no depende del generador, por concecuencia no le interesa la convergencia. Lo que a su vez genera el problema de {\it mode dropping}.

                    Una mejora sustancial al modelo ocurre al modificar la función de perdida. Muchos modelos GAN usan la función de perdida conocida como Wassertein. La cula funciona aún cuando las distribuciones son disjuntas y decrecen de forma lenta. 

                    

                \subsection{Deep convolutional GAN}

                    %Aquí agregar un resumen de los problemas de este modelo y cómo se han ido satisfaciendo las necesadidades haciendo modificaciones en las funciones de perdida, los optimizadores, las matodologías y las arquitecturas, para intoduci a los modelos con los que estamos trabajando 
                    
                \subsection{FastGAN}

                \subsection{styleGAN}

            
            


        \printbibliography
        \nocite{*}
        \backmatter%@sglvgdor

    \end{document}


